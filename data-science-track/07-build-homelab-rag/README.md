# Homelab RAG Service

A self-hosted Retrieval-Augmented Generation (RAG) demo for your homelab docs. This repo shows how to:

1. **Paraphrase** source docs into a clean, uniform JSONL
2. **Chunk & embed** them with `BAAI/bge-base-en-v1.5`
3. **Index** embeddings in FAISS for ultra-fast similarity search
4. **Serve** a QA API + simple web UI with FastAPI + OpenAI/Mistral

## ğŸš€ Features

- **Synthetic paraphrasing** pipeline to normalize your documents
- **Configurable chunk size & overlap** for maximal retrieval recall
- **Batch embedding** via Sentence-Transformers + custom â€œrepresentâ€ prompt
- **FAISS** vector store (flat L2) for instant k-NN lookup
- **FastAPI** endpoints:
  - `POST /qa` â€“ answer questions with contextual retrieval + LLM
  - `POST /chunks` â€“ inspect raw chunks returned by FAISS
- **Minimal web UI** (HTML/JS/CSS) for interactive question answering

## ğŸ› ï¸ Prerequisites

- Python 3.10+
- An **OpenAI API key** (if using OpenAI for generation)
- GPU recommended for local LLM inference

## ğŸ“¥ Installation

1. **Clone** this repo
  ```bash
  git clone https://github.com/Kelcode-Dev/kelcode-ai-labs
  cd data-science-track/07-build-homelab-rag
  ```

2. **Create a venv & install deps**

  ```bash
  python -m venv .venv
  source .venv/bin/activate
  pip install -r requirements.txt
  ```

3. **Set** your OpenAI key

  ```bash
  export OPENAI_API_KEY="sk-..."
  ```

## ğŸ”„ Data Prep

Run the seed and paraphrase scripts to assemble your JSONL of homelab docs:

```bash
python seed_documents/seed_homelab_docs.py
python scripts/paraphrase_with_mixtral.py
```

## ğŸ”— Chunk & Embed

Split each paraphrased doc into overlapping passages, batchâ€encode them with a retrieval prompt, then build a FAISS index:

```bash
python scripts/chunk_and_embed.py
```

This will write:

* `embedded_chunks/index.faiss`
* `embedded_chunks/metadata.json`

## ğŸš€ Serve & Query

Start the FastAPI app:

```bash
uvicorn app:app --reload --host 0.0.0.0 --port 8080
```

Use `curl` or the minimal web UI at `http://localhost:8080`:

```bash
# QA
curl -X POST http://localhost:8080/qa \
  -H "Content-Type: application/json" \
  -d '{"question":"How to set up Grafana with Postgres?"}'

# Inspect raw chunks
curl -X POST http://localhost:8080/chunks \
  -H "Content-Type: application/json" \
  -d '{"question":"Docker logging with Loki"}'
```

## ğŸ“‚ Directory Structure

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ embedded_chunks
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ metadata.json
â”œâ”€â”€ paraphrased_documents
â”‚   â””â”€â”€ mixtral_paraphrased.jsonl
â”œâ”€â”€ seed_documents
â”‚   â”œâ”€â”€ seed_docs.jsonl
â”‚   â””â”€â”€ seed_homelab_docs.py
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ chunk_and_embed.py
â”‚   â””â”€â”€ paraphrase_with_mixtral.py
â”œâ”€â”€ static
â”‚   â”œâ”€â”€ rag.js
â”‚   â””â”€â”€ styles.css
â”œâ”€â”€ templates
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ¯ Next Steps

In the **next article**, weâ€™ll cover **testing & validating** your RAG pipeline:

* Evaluate retrieval quality (recall\@k, human review)
* Measure end-to-end performance
* Fine-tune prompts & models for your homelab docs

## ğŸ¤ Contributing

Feel free to open issues or submit PRs. Letâ€™s make homelab RAG rock!

**Key updates**
- Paths under `scripts/` and `seed_documents/` now match your tree
- Removed the Docker/Mongo mention since it isnâ€™t used here
- Unified port (`8080`) across serve & example calls
- Added a brief **Contributing** section to invite feedback
